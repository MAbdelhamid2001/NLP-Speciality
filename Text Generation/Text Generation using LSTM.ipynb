{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39925885-cad2-47a5-afaa-bd6678b368e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb0b93e-4208-440f-a065-f5fcf3693782",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e985163-c351-48fd-9bf4-b06423cb3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_file,encoding='utf-8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187a35a8-63da-4ae2-a574-ebfb719dbbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e7917c-585b-47d3-a692-a29ac24c4bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fdde2-9f70-4b30-852b-a746bd0967d3",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c37e77b-5675-45a5-9a42-220a687aafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char=dict(enumerate(vocab))\n",
    "char2idx = {w:i for i,w in idx2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5252d79-1a20-4b46-823d-a288e69eccd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7d24948-44b2-4e71-b615-bb9906ac8331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbd83f59-9997-4772-bb5e-678c2ba6040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = np.array([char2idx[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3dac2c3-6d69-418c-ae54-8a4d7e26b343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80551bef-08e6-402b-a71d-4ca109e2bb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('First Citi', array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47], dtype=int32))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10],encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2fef5f4-5acc-44ff-bbad-43a1f312870f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d41a050f-ff89-4a1f-a0e9-8c1bbda8f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset=tf.data.Dataset.from_tensor_slices(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f4f5b-5b91-479f-80e6-6bd38b1852ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "36a8f77c-c79d-4ee5-ba68-3fb81eb6ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7264fb9f-8218-420c-8d03-b3a2b5dd7562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(5):\n",
    "    print(index2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4e906336-5334-4110-b6ba-6ab6bc296fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch method easily convert data into sequences of desired size\n",
    "sequences=char_dataset.batch(batch_size=seq_len+1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "56fc6c50-b9cf-463a-9f90-73eb16219863",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "52b0058a-e8ec-4b81-888d-13345cb3a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for i in sequences.take(1):\n",
    "    print(repr(''.join(index2char[i.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "34a1736c-b6e4-4628-85e7-dcc6f1ca1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(chunk):\n",
    "    x =chunk[:-1]\n",
    "    y =chunk[1:]\n",
    "    return x,y\n",
    "dataset=sequences.map(shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "57b4d221-c485-4822-bcbd-92d7122d7e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59], shape=(100,), dtype=int32) tf.Tensor(\n",
      "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
      " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
      "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
      " 37 53 59  1], shape=(100,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i ,t in dataset.take(1):\n",
    "    print(i,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "af82dcae-7868-4b64-b371-44e962d5201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9e39b9cc-fc06-4d8c-ba22-0fee81221f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches=len(text)//(64*100)\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d40f9e75-813f-46d1-a03d-b28a7884cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e6823674-a2b7-43b8-9a74-89ebfbbe65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model,Input,Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a493bbfa-6861-41fb-9ced-f19fd9249852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(batch_shape=[batch_size, None]),\n",
    "        layers.Embedding(vocab_size, embedding_dim),\n",
    "        layers.LSTM(rnn_units,return_sequences=True,stateful=True,dropout=0.2),\n",
    "        layers.LSTM(rnn_units,return_sequences=True,stateful=True,dropout=0.2),\n",
    "        layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d11c9cd7-bda9-428d-ad91-e55e0bbda9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "embed_dim=256\n",
    "units=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7a9f6ded-996b-4009-a277-5c6740807cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embedding_dim=embed_dim,\n",
    "  rnn_units=units,\n",
    "  batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029df28-63ba-441f-b5fe-71113c0a6896",
   "metadata": {},
   "source": [
    "- `stateful=True` treat batches like a long continuous sequence\n",
    "  \n",
    "    - as it keeps the hidden stats between batches to remember sequence across batches\n",
    "    - it requires `n_batches` to be fixed and manually do `model.reset_states()` after each epoch\n",
    "- `stateful=False` after each batch LSTM resets its hidden state ,forget everything before the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4b561c0a-5d2c-4f51-aef3-05bdb64e5f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,250</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,225</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │           \u001b[38;5;34m3,250\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m29,440\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)              │           \u001b[38;5;34m4,225\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,915</span> (144.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,915\u001b[0m (144.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,915</span> (144.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,915\u001b[0m (144.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b140e36c-4575-4f12-ae44-1bf9e78b909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livelossplot.tf_keras import PlotLossesCallback\n",
    "ck_point=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='text_gen.weights.h5',\n",
    "    save_weights_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "05af95af-e987-48b2-b983-5cb116377975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels,logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3b00ec80-07f0-47a0-b75d-cdef685905f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "03926f42-35cc-4e98-a778-9128d5aa8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('text_gen.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c68de495-f032-46cf-97c3-f985ddb08083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 1.5913\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5905\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 1.5897\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5890\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5882\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5874\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5866\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5859\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5851\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 1.5844\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 1.5836\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5829\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5821\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5815\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5807\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 1.5801\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5794\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5788\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5781\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 1.5775\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5768\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5762\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 1.5755\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 1.5749\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 1.5743\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 1.5737\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 1.5730\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5725\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5719\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 1.5714\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 1.5707\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 1.5702\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 1.5697\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 1.5692\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 1.5686\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 1.5681\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 1.5675\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 1.5671\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 1.5665\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 1.5661\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 1.5655\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 1.5651\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 1.5645\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 1.5640\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 1.5635\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 1.5631\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5627\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 1.5621\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5617\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.5612\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}/{epochs}\\n\")\n",
    "    model.fit(dataset,epochs=1,callbacks=[ck_point],shuffle=False)\n",
    "    for layer in model.layers:\n",
    "            if hasattr(layer,'reset_states'):\n",
    "                layer.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbee4b-6b9f-439e-9490-00aebb65ef58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a406a-8a7b-4937-b642-28718b3836c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Try GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf70ca-7530-43c4-a313-05dff1b42f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ace38c73-3f0e-440b-88b7-42984472d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594aabfb-0b84-4f4d-a4ce-cc2d7c206b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4981b-03e8-4572-b80a-1cf2f84e4eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff858da4-91f0-494c-b060-ed5769d12551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f38d3-2976-40f3-87b1-f18792162f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7796ee-27e7-48be-acad-e43cb79a632e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054c798-85f6-440e-a769-9b5ba4139ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18668ac6-d385-4bb7-ac95-f175f85c31ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d407c-71c8-4bc0-9457-4bac2734e641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25b6dee3-123b-4185-9a25-b68e5502f66f",
   "metadata": {},
   "source": [
    "# make prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402bd70-cd8c-4d6d-b62e-81fb86bc46e7",
   "metadata": {},
   "source": [
    "we give the model the starting string ,and every output is fed again as input to predictthe next "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "99a88fd9-581c-4027-8c30-ea7e3df71fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "string=u\"ROMEO: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a5549254-c200-4a91-a812-c70d489475e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string=[char2idx[i] for i in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2da8d7a1-2cc5-4883-b8a7-187aa86fbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = tf.expand_dims(input_string,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "de62a264-a2d9-4fa5-8732-92691a3a815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[30, 27, 25, 17, 27, 10,  1]], dtype=int32)>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "16e839e6-ace8-4bf6-9309-01b949d86205",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if hasattr(layer,'reset_states'):\n",
    "        layer.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4469d744-7f3a-41d9-bf76-9cda862a2138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "32ca8054-c8c9-47bc-bf19-6aa105560721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 7, 65)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af32af7-d51b-4bea-be2b-0492d47ab6a0",
   "metadata": {},
   "source": [
    "rebuild the model by keeping architecture but change batch size to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb62b5-e2e3-440d-a09e-6f0a121e59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=build_model(vocab_size,embed_dim,units,batch_size=1)\n",
    "model2.load_weights('text_gen.weights.h5')\n",
    "model2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5e071336-8adf-477b-97ae-5a8b0b5659cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=model2.predict(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cb925f13-0fef-4ecb-b569-1388dc47b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 65)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d4ba31fe-0dce-41d4-b4f4-81d12798ce24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 65])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tf.squeeze(prediction, 0)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c9d05b46-0b3f-4667-a218-adfb62b8978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=tf.random.categorical(pred,num_samples=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e019c61e-b16a-468d-aa5f-604a72d566cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47],\n",
       "       [10],\n",
       "       [17],\n",
       "       [10],\n",
       "       [26],\n",
       "       [ 0],\n",
       "       [21]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0ca45f7f-2756-4302-bdd6-26cf9a780be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(index2char[p[-1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "347b9f19-e9bd-4e67-b2d4-931b0fa277e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(21)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.categorical(pred[-1:],num_samples=1)[-1,0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24040b-261a-47f7-a4dc-eee73e734d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f34e0-0842-4611-a87c-56a1ebbaa2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "80b3349e-2432-4f5c-989f-92a40a1becf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,start_str,num_gen=1000):\n",
    "    input_string=[char2idx[i] for i in start_str]\n",
    "    input_string = tf.expand_dims(input_string,0)\n",
    "    print(input_string.shape)\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer,'reset_states'):\n",
    "            layer.reset_states()\n",
    "    generated_text=[]\n",
    "    # low temp --> more predictable text more coherent\n",
    "    # high --> more surprising text\n",
    "    temperature=.3 #  \n",
    "\n",
    "    for i in range (num_gen):\n",
    "        prediction=model(input_string)\n",
    "        pred= tf.squeeze(prediction,0)\n",
    "        pred=pred/temperature\n",
    "\n",
    "        pred_id=tf.random.categorical(pred[-1:],num_samples=1)[-1,0].numpy()\n",
    "        input_string = tf.concat([input_string, [[pred_id]]], axis=-1)\n",
    "        generated_text.append(index2char[pred_id])\n",
    "        \n",
    "    return start_str + ''.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "88682089-a71a-4797-ba86-cd1ffe9a05c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ROMEO: I have so stand the comes she shall death the words the come to the have to the rath with to me the '"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model2,start_str=u\"ROMEO: \",num_gen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6abddd1-b5f5-42dd-9cf0-ebbbfe930a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417f1b7-3ea0-4298-9169-1778d20a6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ROMEO: Why 'it\\nLefur, furbhter a rather or thought ceeress fair atquarty priths\\nThat you shone, now\\nsirets convery me my weach meet, we this goner:\\nYou and grace, which and and lord, God; My a pyshert: yet m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b2d84-0f53-4fc2-9472-a0286f14e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change temperature \n",
    "# number of layer \n",
    "# use bi-lstm\n",
    "# more ebpochs =30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6af512-9fef-40d9-9064-635f8b456828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a44c23-9849-4bb3-991d-13f1a788b2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1a273-f0d8-45f5-b8e4-7b158e0ef948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a736b6-7d88-4270-9097-b30130a123c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(batch_shape=[batch_size, None]),\n",
    "        layers.Embedding(vocab_size, embedding_dim),\n",
    "        layers.LSTM(rnn_units, return_sequences=True, stateful=True),\n",
    "        layers.Dense(vocab_size, activation='softmax')  # Add softmax\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Then change loss function:\n",
    "def loss(labels, predictions):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, predictions, from_logits=False  # Change to False\n",
    "    )\n",
    "\n",
    "# And in generation, skip the softmax step:\n",
    "def generate_text(model, start_str, num_gen=1000, temperature=1.0):\n",
    "    # ...\n",
    "    predictions = model(input_eval)\n",
    "    predictions = tf.squeeze(predictions, 0)[-1, :]\n",
    "    \n",
    "    # Already probabilities, but can still apply temperature:\n",
    "    # (though this is less clean mathematically)\n",
    "    predictions = tf.math.pow(predictions, 1/temperature)\n",
    "    predictions = predictions / tf.reduce_sum(predictions)\n",
    "    \n",
    "    predicted_id = tf.random.categorical(\n",
    "        tf.expand_dims(tf.math.log(predictions), 0),  # Need log for categorical\n",
    "        num_samples=1\n",
    "    )[-1, 0].numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
