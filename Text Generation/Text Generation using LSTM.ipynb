{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39925885-cad2-47a5-afaa-bd6678b368e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb0b93e-4208-440f-a065-f5fcf3693782",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e985163-c351-48fd-9bf4-b06423cb3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_file,encoding='utf-8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187a35a8-63da-4ae2-a574-ebfb719dbbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e7917c-585b-47d3-a692-a29ac24c4bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fdde2-9f70-4b30-852b-a746bd0967d3",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae4ddbd-8357-4e64-8ef1-2a717839bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char=np.array(vocab)\n",
    "char2idx = {w:i for i,w in enumerate( idx2char)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd83f59-9997-4772-bb5e-678c2ba6040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = np.array([char2idx[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80551bef-08e6-402b-a71d-4ca109e2bb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('First Citi', array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10],encoded[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50d6320-4b4a-4edb-adbc-0f4589d2b1e3",
   "metadata": {},
   "source": [
    "## 1st method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf16b560-069d-47e1-bfaf-14418c20b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    # Get the number of characters per batch and number of batches we can make\n",
    "    batch_size = n_seqs * n_steps\n",
    "    n_batches = len(arr)//batch_size #k\n",
    "    print(n_batches)\n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches*batch_size]\n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape((n_seqs,-1))\n",
    "    print(arr.shape)\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:,n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        y[:,:-1],y[:,-1]=x[:,1:],x[:,0]\n",
    "        \n",
    "        x_train.append(x)\n",
    "        y_train.append(y)\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68addf49-d095-43ed-a2a1-1ad66805ae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "(64, 17400)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = get_batches(encoded, n_seqs=64, n_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "803c0ee9-bb80-49f0-b7d8-1af206267ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((174, 64, 100), (174, 64, 100))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array(x_train)\n",
    "y=np.array(y_train)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8130fdd2-d7a4-4f81-8998-38d58821222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices((x,y)).shuffle(buffer_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa85d683-8b36-43c2-a611-e51b48017c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n"
     ]
    }
   ],
   "source": [
    "for i,j in dataset.take(1):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1249f319-d928-45f4-bf13-11a975893bf7",
   "metadata": {},
   "source": [
    "## 2nd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d41a050f-ff89-4a1f-a0e9-8c1bbda8f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset=tf.data.Dataset.from_tensor_slices(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e906336-5334-4110-b6ba-6ab6bc296fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch method easily convert data into sequences of desired size\n",
    "seq_len = 100\n",
    "sequences=char_dataset.batch(batch_size=seq_len+1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "34a1736c-b6e4-4628-85e7-dcc6f1ca1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(chunk):\n",
    "    x =chunk[:-1]\n",
    "    y =chunk[1:]\n",
    "    return x,y\n",
    "dataset=sequences.map(shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "57b4d221-c485-4822-bcbd-92d7122d7e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59], shape=(100,), dtype=int32) tf.Tensor(\n",
      "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
      " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
      "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
      " 37 53 59  1], shape=(100,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i ,t in dataset.take(1):\n",
    "    print(i,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "af82dcae-7868-4b64-b371-44e962d5201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9e39b9cc-fc06-4d8c-ba22-0fee81221f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches=len(text)//(64*100)\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d40f9e75-813f-46d1-a03d-b28a7884cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e527447-d447-4d45-b615-43a8ea19f61e",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e6823674-a2b7-43b8-9a74-89ebfbbe65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model,Input,Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a493bbfa-6861-41fb-9ced-f19fd9249852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Input(batch_shape=[batch_size, None]),\n",
    "        layers.Embedding(vocab_size, embedding_dim),\n",
    "        layers.LSTM(rnn_units,return_sequences=True,stateful=True,dropout=0.2),\n",
    "        layers.LSTM(rnn_units,return_sequences=True,stateful=True,dropout=0.2),\n",
    "        layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d11c9cd7-bda9-428d-ad91-e55e0bbda9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "embed_dim=100\n",
    "units=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a9f6ded-996b-4009-a277-5c6740807cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embedding_dim=embed_dim,\n",
    "  rnn_units=units,\n",
    "  batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029df28-63ba-441f-b5fe-71113c0a6896",
   "metadata": {},
   "source": [
    "- `stateful=True` treat batches like a long continuous sequence\n",
    "  \n",
    "    - as it keeps the hidden stats between batches to remember sequence across batches\n",
    "    - it requires `n_batches` to be fixed and manually do `model.reset_states()` after each epoch\n",
    "- `stateful=False` after each batch LSTM resets its hidden state ,forget everything before the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b561c0a-5d2c-4f51-aef3-05bdb64e5f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,385</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │           \u001b[38;5;34m6,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m117,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m131,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)              │           \u001b[38;5;34m8,385\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">263,717</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m263,717\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">263,717</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m263,717\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b140e36c-4575-4f12-ae44-1bf9e78b909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from livelossplot.tf_keras import PlotLossesCallback\n",
    "ck_point=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='text_gen.weights.h5',\n",
    "    save_weights_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "05af95af-e987-48b2-b983-5cb116377975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels,logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3b00ec80-07f0-47a0-b75d-cdef685905f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "03926f42-35cc-4e98-a778-9128d5aa8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('text_gen1.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c68de495-f032-46cf-97c3-f985ddb08083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 2.9606\n",
      "Epoch 1/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 2.4128\n",
      "Epoch 2/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 2.2789\n",
      "Epoch 3/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 2.1963\n",
      "Epoch 4/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 2.1356\n",
      "Epoch 5/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 2.0879\n",
      "Epoch 6/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 2.0490\n",
      "Epoch 7/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 2.0148\n",
      "Epoch 8/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 1.9862\n",
      "Epoch 9/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 1.9614\n",
      "Epoch 10/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 1.9392\n",
      "Epoch 11/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 1.9199\n",
      "Epoch 12/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 1.9039\n",
      "Epoch 13/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 1.8895\n",
      "Epoch 14/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 1.8773\n",
      "Epoch 15/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 1.8663\n",
      "Epoch 16/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 1.8563\n",
      "Epoch 17/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 1.8465\n",
      "Epoch 18/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 1.8383\n",
      "Epoch 19/20\n",
      "\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 1.8312\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}/{epochs}\\n\")\n",
    "    model.fit(dataset,epochs=1,callbacks=[ck_point],shuffle=False)\n",
    "    for layer in model.layers:\n",
    "            if hasattr(layer,'reset_states'):\n",
    "                layer.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6dee3-123b-4185-9a25-b68e5502f66f",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402bd70-cd8c-4d6d-b62e-81fb86bc46e7",
   "metadata": {},
   "source": [
    "we give the model the starting string ,and every output is fed again as input to predictthe next "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99a88fd9-581c-4027-8c30-ea7e3df71fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "string=u\"ROMEO: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5549254-c200-4a91-a812-c70d489475e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string=[char2idx[i] for i in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2da8d7a1-2cc5-4883-b8a7-187aa86fbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = tf.expand_dims(input_string,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de62a264-a2d9-4fa5-8732-92691a3a815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[30, 27, 25, 17, 27, 10,  1]], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16e839e6-ace8-4bf6-9309-01b949d86205",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if hasattr(layer,'reset_states'):\n",
    "        layer.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4469d744-7f3a-41d9-bf76-9cda862a2138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32ca8054-c8c9-47bc-bf19-6aa105560721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 7, 65)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af32af7-d51b-4bea-be2b-0492d47ab6a0",
   "metadata": {},
   "source": [
    "rebuild the model by keeping architecture but change batch size to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ceb62b5-e2e3-440d-a09e-6f0a121e59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=build_model(vocab_size,embed_dim,units,batch_size=1)\n",
    "model2.load_weights('text_gen1.weights.h5')\n",
    "model2.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e071336-8adf-477b-97ae-5a8b0b5659cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=model2.predict(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb925f13-0fef-4ecb-b569-1388dc47b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 65)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4ba31fe-0dce-41d4-b4f4-81d12798ce24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([7, 65])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tf.squeeze(prediction, 0)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9d05b46-0b3f-4667-a218-adfb62b8978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=tf.random.categorical(pred,num_samples=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e019c61e-b16a-468d-aa5f-604a72d566cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15],\n",
       "       [19],\n",
       "       [ 7],\n",
       "       [30],\n",
       "       [26],\n",
       "       [ 0],\n",
       "       [42]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ca45f7f-2756-4302-bdd6-26cf9a780be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx2char[p[-1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "347b9f19-e9bd-4e67-b2d4-931b0fa277e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(46)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=tf.random.categorical(pred[-1:],num_samples=1)[-1,0].numpy()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51e1c976-e26b-4639-8231-23fbff881770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx2char[p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a12f9e-2323-48e9-8668-dd75c174c71c",
   "metadata": {},
   "source": [
    "## Make final generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80b3349e-2432-4f5c-989f-92a40a1becf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,start_str,num_gen=1000):\n",
    "    input_string=[char2idx[i] for i in start_str]\n",
    "    input_string = tf.expand_dims(input_string,0)\n",
    "    print(input_string.shape)\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer,'reset_states'):\n",
    "            layer.reset_states()\n",
    "    generated_text=[]\n",
    "    # low temp --> more predictable text more coherent\n",
    "    # high --> more surprising text\n",
    "    temperature=.3 #  \n",
    "\n",
    "    for i in range (num_gen):\n",
    "        prediction=model(input_string)\n",
    "        pred= tf.squeeze(prediction,0)\n",
    "        pred=pred/temperature\n",
    "\n",
    "        pred_id=tf.random.categorical(pred[-1:],num_samples=1)[-1,0].numpy()\n",
    "        # concatebate the previous inputs with current to be fed together to predict next char\n",
    "        input_string = tf.concat([input_string, [[pred_id]]], axis=-1)\n",
    "        generated_text.append(idx2char[pred_id])\n",
    "        \n",
    "    return start_str + ''.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88682089-a71a-4797-ba86-cd1ffe9a05c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello make the prome\\nThe countred the some and the stand the she meed the aring the with the death and wit'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model2,start_str=u\"Hello \",num_gen=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
