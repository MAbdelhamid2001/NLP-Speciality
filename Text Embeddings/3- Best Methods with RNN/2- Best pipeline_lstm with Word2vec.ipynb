{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c4c8e5-92c6-4920-9af9-7f289e050528",
   "metadata": {},
   "source": [
    "## import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66efdbf6-a0d5-4755-a7d2-7ff8cd69f8b9",
   "metadata": {},
   "source": [
    "vectors generated by Spacy gained from pre-trained GloVe model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a84dde-07cf-4014-ae7a-2c642299d816",
   "metadata": {},
   "source": [
    "<center><h1>N-grams with Word embeddings</h1></center>\n",
    "\n",
    "How can we incorporate N-Grams features with our word embedding, we use **convolution**.\n",
    "\n",
    "The window size indicate the N in N-gram, like for example if the kernel size is `3x300`, this means 3-grams model and so on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ecdddb-240c-4403-bb2a-da76bf019557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad39cb3-b8db-4502-bd2a-b259009df94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat tag map between treebank and wordnet\n",
    "# tree bank : collection of syntactically annotated sentences\n",
    "tag_map = {\n",
    "\"CC\": None, #formatted. conjunction (and, but, or)\n",
    "'CD': wn.NOUN, # original number (one,two)\n",
    "'DT': None, # delimiter (a, the)\n",
    "'EX': wn.ADV, #and my \"there\" (there)\n",
    "\"FW\": None, # foreign word (mea culpa)\n",
    "\"IN\": wn.ADV,# preposition/subjunctive conjunction (of, in,by) \n",
    "'JJ': [wn.ADJ, wn.ADJ_SAT],# adjective # (yellow)\n",
    "'JJR': [wn.ADJ, wn.ADJ_SAT], # add, comparator (larger)\n",
    "\"JJS\": [wn.ADJ, wn.ADJ_SAT], # add, superlative (wildest)\n",
    "\"LS\": None, #list item tag(1,2,One)\n",
    "'MD': None, # modal (can, should)\n",
    "'NN': wn.NOUN, #noun, sing. or nugget (llama)\n",
    "'NNS': wn.NOUN, #noun, plural (Llamas)\n",
    "\"NNP\": wn.NOUN, # proper noun, vocals. (IBM)\n",
    "'NNPS': wn.NOUN, # proper noun, plural (Carolina)\n",
    "\"PDT\": [wn.ADJ, wn.ADJ_SAT], # predeterminer (all, both)\n",
    "'POS':None, # end of ownership\n",
    "'PRP': None, # personal pronoun (I, you, he)\n",
    "'prp$': None, # possessive pronoun (your, one's)\n",
    "\"RB\": wn.ADV, #adv (quickly, never)\n",
    "'RBR': wn.ADV, # adverb, comparative (faster)\n",
    "'RBS':wn.ADV,# adverb, superlative (fastest)\n",
    "'RP': [wn.ADJ, wn.ADJ_SAT], # particle (up, off)\n",
    "'SYM': None, #symbol, # (+, %, &)\n",
    "'TO': None, # 'to' (to)\n",
    "'UH': None, # interjection (uh, oops)\n",
    "'VB': wn.VERB,# verb base form # (eat)\n",
    "'VBD': wn.VERB, # verb past tense (eat)\n",
    "'VBG': wn.VERB, #verb gerund (to eat)\n",
    "'VBN': wn.VERB, # past participle (eaten)\n",
    "\"VBP\": wn.VERB, #non-3sg pres verb (eat)\n",
    "'VBZ': wn.VERB,# verb зsg pres (egts) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb547be-fc1a-41a2-815a-2eb23af9b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma=WordNetLemmatizer()\n",
    "def get_lemma(text):\n",
    "    l=[]\n",
    "    tags=pos_tag(text.split())\n",
    "    for token,tag in tags:\n",
    "        try:\n",
    "             l.append(lemma.lemmatize(token,pos=tag_map[tag][0]))\n",
    "        except:\n",
    "            continue\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49cfe39-4cd3-4f43-8208-6637f1124b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "def cleaning(df):\n",
    "    \"\"\"\n",
    "    - remove empty strings\n",
    "    - remove duplicates\n",
    "    \"\"\"\n",
    "    # remove empty string\n",
    "    blanks=[]\n",
    "    for i ,v in df.itertuples():\n",
    "        if v.isspace() ==True or v=='':\n",
    "            blanks.append(i)\n",
    "    if len(blanks)>0:\n",
    "        df=df.drop(blanks)\n",
    "        print(f\"found {colored(len(blanks),'red')} blanks\")\n",
    "    else:\n",
    "        print(\"no blanks found\")\n",
    "\n",
    "    # remove duplicates\n",
    "    if df.duplicated().sum() !=0:\n",
    "        print(f\"dropped {colored(df.duplicated().sum(),'red')} : values\")\n",
    "        df=df.drop_duplicates()\n",
    "    else:\n",
    "        print(\"no duplicates found\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6db6b2-b4ce-4977-86cc-63eafb97fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def preprocessing(df,col):\n",
    "    # lowercasing\n",
    "    df[col]=df[col].apply(lambda x: \" \".join(t.lower() for t in x.split()))\n",
    "    # remove emails\n",
    "    df[col]=df[col].apply(lambda x: re.sub(\"\\S+\\@\\S+\",'',x))\n",
    "    # remove URls\n",
    "    df[col]=df[col].apply(lambda x: re.sub(\"\\S+\\.\\S+\",'',x))\n",
    "    # remove punctations\n",
    "    df[col]=df[col].apply(lambda x: re.sub(f'[{re.escape(string.punctuation)}]',' ',x))\n",
    "    # remove stopwords\n",
    "    df[col]=df[col].apply(lambda x :\" \".join(t for t in x.lower().split() if t not in stop))\n",
    "    # remove \\n or \\t\n",
    "    df[col]=df[col].apply(lambda x: re.sub('\\n|\\t',' ',x))\n",
    "    # remove 2 characters words\n",
    "    df[col]=df[col].apply(lambda x: re.sub(r' \\w\\w ',' ',x) )\n",
    "    # remove 1 character words\n",
    "    df[col]=df[col].apply(lambda x: re.sub(r' \\w ',' ',x) )\n",
    "    # remove extra spaces more than or equals \"2\" \n",
    "    df[col]=df[col].apply(lambda x: re.sub(\" {2,}\",' ',x))\n",
    "    # select alphapetical only\n",
    "    df[col]=df[col].apply(lambda x: re.sub(\"[^a-z]+\",' ',x) )\n",
    "    # strip string\n",
    "    df[col]=df[col].apply(lambda x: x.strip())\n",
    "    # get lemma\n",
    "    df[col]=df[col].apply(lambda x: \" \".join(get_lemma(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6633969-6a92-4a93-b460-ffe750e5945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty strings  \n",
    "# remove duplicates \n",
    "# remove 1 character words\n",
    "# remove 2 characters words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a19660b-6ffc-4bcc-9f5c-da7f9189cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'smsspamcollection.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c7d3f3e-38bd-44f9-9b5e-ecdbdb7b6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['message']\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c8fed76-1690-4362-a30c-4798830a9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f096155b-6197-4aa8-91fb-50777b598f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(X_train,columns=['message'])\n",
    "x_test=pd.DataFrame(X_test,columns=['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf72c456-8efd-4097-90de-72d9bd60a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no blanks found\n",
      "dropped \u001b[31m210\u001b[0m : values\n",
      "no blanks found\n",
      "dropped \u001b[31m65\u001b[0m : values\n"
     ]
    }
   ],
   "source": [
    "cleaned_train=cleaning(x_train)\n",
    "cleaned_test=cleaning(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24211d08-d8ed-4560-9e08-ec9d548abb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3fedf38-1ce9-4e49-b2fa-906e160dda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train=preprocessing(cleaned_train,col='message')\n",
    "prep_test=preprocessing(cleaned_test,col='message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93c9357f-4d0f-4313-9683-8ff1d61186d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train[prep_train.index]\n",
    "y_test=y_test[prep_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f97f55de-9ee4-4cf3-a6b3-7e59a2c16f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a273d05-3d8c-40e9-88ff-55fcfab30cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longest_text(texts):\n",
    "    longest=0\n",
    "    for text in texts:\n",
    "        text_len=len(text.split())\n",
    "        longest=max(text_len,longest)\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "063db950-3557-4e37-a28c-7de1262ce75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_input=get_longest_text(prep_train['message'])\n",
    "longest_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f484e1-906c-49da-b20a-216d8fb4fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of messages ,no of tokens ,vector\n",
    "# message --> have 66 token -->each token has 300 vecto size\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4552426c-e968-4737-b85b-33d22ec7a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb=np.zeros((len(prep_train),longest_input,300))\n",
    "test_emb=np.zeros((len(prep_test),longest_input,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eae200ad-3601-4847-90e4-ee32020c97eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(61, 300))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d42d9e18-216b-4df8-8a52-07cd8b34a07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb7b83bbc8545db9bcb2abb33df96d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for i ,text in tqdm(enumerate(nlp.pipe(prep_train['message'])),total=(len(prep_train))):\n",
    "    for j , token in enumerate(text):\n",
    "        train_emb[i,j]=token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ead2a664-26a4-4aac-9353-b2d402ee60b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34494270fa134676bd2c62ac3eb94fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for i ,text in tqdm(enumerate(nlp.pipe(prep_test['message'])),total=(len(prep_test))):\n",
    "    for j , token in enumerate(text):\n",
    "        test_emb[i,j]=token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "406b388c-219f-449f-a622-0fd760a6e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input,Reshape,Conv2D,MaxPool2D,Flatten,Dense,concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0baa121b-bddf-41b4-86aa-fab14ca8f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c90b8bc-b9be-48ec-8311-81b234ccbaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb=LabelEncoder()\n",
    "y_train=lb.fit_transform(y_train)\n",
    "y_test=lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b00a8-4642-4347-97f2-b1464b64706f",
   "metadata": {},
   "source": [
    "# Try LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af17760a-5721-4f4f-962e-a50ee2659a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "557637ee-2a89-445e-adc0-b4c774f8a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input((longest_input, 300))\n",
    "# lstm_1=layers.LSTM(64,return_sequences=True)(inputs)\n",
    "# outputs=layers.Dense(1,activation='sigmoid')(lstm_1)\n",
    "# model=Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a9b7d-5d9e-4efd-98a3-e42a9a9a8890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ddb79a7-19ca-41e5-a2bf-994abbb491ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    # input shape (None, 66, 10000)\n",
    "    # (n_samples,n_time_steps,embed_dimen)\n",
    "    # layers.Embedding(input_dim=vocab_size,output_dim=128,input_length=66),# (None, 66, 300)\n",
    "    layers.LSTM(32,return_sequences=True),#(None, 66) \n",
    "    layers.LSTM(16,return_sequences=True),#(None, 66) \n",
    "    layers.Dropout(0.3),\n",
    "    layers.LSTM(8),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfbed651-4fc0-4c46-9c9b-cd63b9880883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd37021c-8d0b-4823-b962-2e0b6703cf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8545 - loss: 0.5092 - val_accuracy: 0.8596 - val_loss: 0.4001\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9262 - loss: 0.2514 - val_accuracy: 0.9674 - val_loss: 0.1582\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9617 - loss: 0.1442 - val_accuracy: 0.9504 - val_loss: 0.1463\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9748 - loss: 0.1148 - val_accuracy: 0.9589 - val_loss: 0.1559\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9737 - loss: 0.1042 - val_accuracy: 0.9674 - val_loss: 0.1311\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9851 - loss: 0.0811 - val_accuracy: 0.9674 - val_loss: 0.1281\n",
      "Epoch 7/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9627 - loss: 0.1278 - val_accuracy: 0.9645 - val_loss: 0.1252\n",
      "Epoch 8/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9847 - loss: 0.0726 - val_accuracy: 0.9688 - val_loss: 0.1056\n",
      "Epoch 9/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9883 - loss: 0.0642 - val_accuracy: 0.9688 - val_loss: 0.1043\n",
      "Epoch 10/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9908 - loss: 0.0523 - val_accuracy: 0.9674 - val_loss: 0.1177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eedaf8acf0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_emb,y_train,validation_split=0.2,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5dddc76d-56b3-455b-9a48-5ae89c244705",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential([\n",
    "    # input shape (None, 66, 300)\n",
    "    # (n_samples,n_time_steps,embed_dimen)\n",
    "    # layers.Embedding(input_dim=vocab_size,output_dim=100),#output (None, 66, 300)\n",
    "    layers.Bidirectional(layers.GRU(64,return_sequences=True)),\n",
    "    layers.Bidirectional(layers.GRU(64)),\n",
    "    layers.Dense(32,activation='relu'),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "\n",
    "])\n",
    "# 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7149010-4d51-4ae4-96d3-4e8eaa94197c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e1c2b91-eec3-47fd-9943-f4d80a9eda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f97a135-9ebe-4e32-9440-a6ca5889740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.9056 - loss: 0.2525 - val_accuracy: 0.9631 - val_loss: 0.1100\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9705 - loss: 0.0810 - val_accuracy: 0.9702 - val_loss: 0.1029\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9833 - loss: 0.0502 - val_accuracy: 0.9773 - val_loss: 0.0973\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9894 - loss: 0.0339 - val_accuracy: 0.9716 - val_loss: 0.1011\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9933 - loss: 0.0211 - val_accuracy: 0.9702 - val_loss: 0.1066\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9950 - loss: 0.0133 - val_accuracy: 0.9674 - val_loss: 0.1318\n",
      "Epoch 7/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9730 - val_loss: 0.1308\n",
      "Epoch 8/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 9.3487e-04 - val_accuracy: 0.9730 - val_loss: 0.1467\n",
      "Epoch 9/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.6966e-04 - val_accuracy: 0.9716 - val_loss: 0.1536\n",
      "Epoch 10/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.2325e-04 - val_accuracy: 0.9716 - val_loss: 0.1601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eedb254690>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_emb,y_train,validation_split=0.2,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6378564-68f7-48f5-ab5e-e05e63accf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f6756c2-f3fc-4575-99be-adefc14e5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Once upon a time, there was a little village...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "942c5920-5841-414e-a62c-afff3271f1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, there was a little village...'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef2741f-456f-422f-bdf3-a9efe592e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce65a6ba-c0a5-483c-8340-da3d20959de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4e729a-c9c9-45be-9784-7a57d131cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c:i for i,c in enumerate(chars)}\n",
    "idx2char = np.array(chars)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c327f0-24a2-46db-ac61-6bfc35d739fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 12,  5,  6,  0, 18, 14, 13, 12,  0,  4,  0, 17,  9, 11,  6,  1,\n",
       "        0, 17,  8,  6, 15,  6,  0, 20,  4, 16,  0,  4,  0, 10,  9, 17, 17,\n",
       "       10,  6,  0, 19,  9, 10, 10,  4,  7,  6,  2,  2,  2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4369acab-af34-4205-93e5-a58cffea027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "step = 3\n",
    "sequences, next_chars = [], []\n",
    "for i in range(0, len(text_as_int)-seq_length, step):\n",
    "    sequences.append(text_as_int[i:i+seq_length])\n",
    "    next_chars.append(text_as_int[i+seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4708a427-60fd-4a79-82f5-16be64da21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.array(sequences), np.array(next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e57e8c9-9df9-4fce-b9f2-f3db12f45cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 40)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cecea580-56ac-449e-8061-47d7af7a1c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd580a3d-f289-47f8-bd05-94e063c30858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 12,  5,  6,  0, 18, 14, 13, 12,  0,  4,  0, 17,  9, 11,  6,\n",
       "         1,  0, 17,  8,  6, 15,  6,  0, 20,  4, 16,  0,  4,  0, 10,  9,\n",
       "        17, 17, 10,  6,  0, 19,  9, 10],\n",
       "       [ 6,  0, 18, 14, 13, 12,  0,  4,  0, 17,  9, 11,  6,  1,  0, 17,\n",
       "         8,  6, 15,  6,  0, 20,  4, 16,  0,  4,  0, 10,  9, 17, 17, 10,\n",
       "         6,  0, 19,  9, 10, 10,  4,  7],\n",
       "       [14, 13, 12,  0,  4,  0, 17,  9, 11,  6,  1,  0, 17,  8,  6, 15,\n",
       "         6,  0, 20,  4, 16,  0,  4,  0, 10,  9, 17, 17, 10,  6,  0, 19,\n",
       "         9, 10, 10,  4,  7,  6,  2,  2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f41a5e-0ec7-4221-9425-b11cd8c44d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build stacked LSTM model\n",
    "vocab_size = len(chars)\n",
    "embedding_dim = 32\n",
    "rnn_units = 64\n",
    "model = Sequential([\n",
    "    layers.Embedding(vocab_size, embedding_dim, input_length=seq_length),\n",
    "    layers.LSTM(rnn_units, return_sequences=True),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(rnn_units),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c9d3fb6-c415-4224-bb7e-ae08715c4b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 3.0474\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.0380\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 3.0297\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.0200\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.0030\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 3.0009\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 2.9706\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 2.9548\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.9103\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.8794\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2.8170\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.7627\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.6675\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.5503\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.3306\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.0939\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.7254\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.7907\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.6102\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.5539\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.3502\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4990\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.4431\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.2339\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4800\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.2587\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.2122\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.3760\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.0155\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.8350\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.9669\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.1200\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.2270\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.4198\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.0733\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.2354\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 1.4276\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 1.3377\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 1.6404\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 1.3824\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.0737\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 1.1552\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0860\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.8392\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.0641\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.1236\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.3742\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8175\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.3951\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.0225\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.6007\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4342\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.6994\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.1345\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.4176\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.2139\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8763\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.4833\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.3020\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.2894\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.1467\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.3237\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.1301\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.0737\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.0319\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.1768\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.4493\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.5027\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.5555\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.8242\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 1.0407\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.3388\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.1921\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.2442\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.7241\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.0733\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.2479\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.4839\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.1187\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.8172\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.9468\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.1453\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.1372\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 1.0616\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 1.1540\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.2381\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.8368\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.1353\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.9022\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.2690\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.9205\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.9333\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.0339\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.0410\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 1.2982\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 1.2506\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.1845\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.2929\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.8246\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x262b148d160>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.fit(x, y, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65181d36-c62d-45f4-84b0-2696c3575480",
   "metadata": {},
   "source": [
    "# Another Way of using GloVe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac90c4-f5e7-42fd-af60-6f7ab65f8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaecc7f-fe48-43d0-b9cc-1d24fb7fe631",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(prep_train['text'])\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54869630-dee1-41f6-8a57-5fcc52b78f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = tokenizer.texts_to_sequences(prep_train['text'])\n",
    "X_test_seq  = tokenizer.texts_to_sequences(prep_test['text'])\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad  = pad_sequences(X_test_seq,  maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5070d69-7a03-4111-8b31-9e53dd31cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating embedding matrix...\")\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < vocab_size:\n",
    "        token = nlp(word)        \n",
    "        if token.has_vector:\n",
    "            embedding_matrix[i] = token.vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "\n",
    "print(f\"Converted {hits} words. Missed {misses} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba4ecb-d1a5-410f-bfc0-bb251f7d7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model2=Sequential([\n",
    "\n",
    "    layers.Embedding(input_dim=vocab_size,output_dim=300,weights=[embedding_matrix],trainable=False),\n",
    "    layers.Bidirectional(layers.LSTM(128,return_sequences=False, recurrent_dropout=0.2)),    \n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax')\n",
    "\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
