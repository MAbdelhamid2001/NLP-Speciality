{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23edf053-760e-47dc-9b0f-df9a75ff8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66efdbf6-a0d5-4755-a7d2-7ff8cd69f8b9",
   "metadata": {},
   "source": [
    "vectors generated by Spacy gained from pre-trained GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ecdddb-240c-4403-bb2a-da76bf019557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad39cb3-b8db-4502-bd2a-b259009df94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat tag map between treebank and wordnet\n",
    "# tree bank : collection of syntactically annotated sentences\n",
    "tag_map = {\n",
    "\"CC\": None, #formatted. conjunction (and, but, or)\n",
    "'CD': wn.NOUN, # original number (one,two)\n",
    "'DT': None, # delimiter (a, the)\n",
    "'EX': wn.ADV, #and my \"there\" (there)\n",
    "\"FW\": None, # foreign word (mea culpa)\n",
    "\"IN\": wn.ADV,# preposition/subjunctive conjunction (of, in,by) \n",
    "'JJ': [wn.ADJ, wn.ADJ_SAT],# adjective # (yellow)\n",
    "'JJR': [wn.ADJ, wn.ADJ_SAT], # add, comparator (larger)\n",
    "\"JJS\": [wn.ADJ, wn.ADJ_SAT], # add, superlative (wildest)\n",
    "\"LS\": None, #list item tag(1,2,One)\n",
    "'MD': None, # modal (can, should)\n",
    "'NN': wn.NOUN, #noun, sing. or nugget (llama)\n",
    "'NNS': wn.NOUN, #noun, plural (Llamas)\n",
    "\"NNP\": wn.NOUN, # proper noun, vocals. (IBM)\n",
    "'NNPS': wn.NOUN, # proper noun, plural (Carolina)\n",
    "\"PDT\": [wn.ADJ, wn.ADJ_SAT], # predeterminer (all, both)\n",
    "'POS':None, # end of ownership\n",
    "'PRP': None, # personal pronoun (I, you, he)\n",
    "'prp$': None, # possessive pronoun (your, one's)\n",
    "\"RB\": wn.ADV, #adv (quickly, never)\n",
    "'RBR': wn.ADV, # adverb, comparative (faster)\n",
    "'RBS':wn.ADV,# adverb, superlative (fastest)\n",
    "'RP': [wn.ADJ, wn.ADJ_SAT], # particle (up, off)\n",
    "'SYM': None, #symbol, # (+, %, &)\n",
    "'TO': None, # 'to' (to)\n",
    "'UH': None, # interjection (uh, oops)\n",
    "'VB': wn.VERB,# verb base form # (eat)\n",
    "'VBD': wn.VERB, # verb past tense (eat)\n",
    "'VBG': wn.VERB, #verb gerund (to eat)\n",
    "'VBN': wn.VERB, # past participle (eaten)\n",
    "\"VBP\": wn.VERB, #non-3sg pres verb (eat)\n",
    "'VBZ': wn.VERB,# verb зsg pres (egts) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb547be-fc1a-41a2-815a-2eb23af9b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma=WordNetLemmatizer()\n",
    "def get_lemma(text):\n",
    "    l=[]\n",
    "    tags=pos_tag(text.split())\n",
    "    for token,tag in tags:\n",
    "        try:\n",
    "             l.append(lemma.lemmatize(token,pos=tag_map[tag][0]))\n",
    "        except:\n",
    "            continue\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49cfe39-4cd3-4f43-8208-6637f1124b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "def cleaning(df):\n",
    "    \"\"\"\n",
    "    - remove empty strings\n",
    "    - remove duplicates\n",
    "    \"\"\"\n",
    "    # remove empty string\n",
    "    blanks=[]\n",
    "    for i ,v in df.itertuples():\n",
    "        if pd.isna(v) or (isinstance(v, str) and (v.strip() == \"\")):\n",
    "            blanks.append(i)\n",
    "    if blanks:\n",
    "        df=df.drop(blanks)\n",
    "        print(f\"found {colored(len(blanks),'red')} blanks\")\n",
    "    else:\n",
    "        print(\"no blanks found\")\n",
    "\n",
    "    # remove duplicates\n",
    "    if df.duplicated().sum() !=0:\n",
    "        print(f\"dropped {colored(df.duplicated().sum(),'red')} : values\")\n",
    "        df=df.drop_duplicates()\n",
    "    else:\n",
    "        print(\"no duplicates found\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6db6b2-b4ce-4977-86cc-63eafb97fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def preprocessing(df,col):\n",
    "\n",
    "     # split quotation marks and words\n",
    "    df[col]=df[col].apply(lambda x: re.sub(r\"([?.!,¿])\", r\" \\1 \", x))\n",
    "    # lowercasing\n",
    "    df[col]=df[col].apply(lambda x: x.lower())\n",
    "    # remove emails\n",
    "    df[col]=df[col].apply(lambda x: re.sub(\"\\S+\\@\\S+\",'',x))\n",
    "    # remove URls\n",
    "    df[col]=df[col].apply(lambda x: re.sub(\"\\S+\\.\\S+\",'',x))\n",
    "    # remove punctations\n",
    "    # df[col]=df[col].apply(lambda x: re.sub(f'[{re.escape(string.punctuation)}]',' ',x))\n",
    "    # remove stopwords\n",
    "    # df[col]=df[col].apply(lambda x :\" \".join(t for t in x.lower().split() if t not in stop))\n",
    "    # remove \\n or \\t\n",
    "    df[col]=df[col].apply(lambda x: re.sub('\\n|\\t',' ',x))\n",
    "    # remove 2 characters words\n",
    "    df[col]=df[col].apply(lambda x: re.sub(r' \\w\\w ',' ',x) )\n",
    "    # remove 1 character words\n",
    "    df[col]=df[col].apply(lambda x: re.sub(r' \\w ',' ',x) )\n",
    "    # remove extra spaces more than or equals \"2\" \n",
    "    df[col]=df[col].apply(lambda x: re.sub(\" {2,}\",' ',x))\n",
    "    # select alphapetical only\n",
    "    df[col]=df[col].apply(lambda x: re.sub(\"[^a-z]+\",' ',x) )\n",
    "    # strip string\n",
    "    df[col]=df[col].apply(lambda x: x.strip())\n",
    "    # get lemma\n",
    "    df[col]=df[col].apply(lambda x: \" \".join(get_lemma(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6633969-6a92-4a93-b460-ffe750e5945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty strings  \n",
    "# remove duplicates \n",
    "# remove 1 character words\n",
    "# remove 2 characters words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a19660b-6ffc-4bcc-9f5c-da7f9189cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'smsspamcollection.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7d3f3e-38bd-44f9-9b5e-ecdbdb7b6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['message']\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c8fed76-1690-4362-a30c-4798830a9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f096155b-6197-4aa8-91fb-50777b598f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.DataFrame(X_train,columns=['message'])\n",
    "x_test=pd.DataFrame(X_test,columns=['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf72c456-8efd-4097-90de-72d9bd60a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no blanks found\n",
      "dropped \u001b[31m210\u001b[0m : values\n",
      "no blanks found\n",
      "dropped \u001b[31m65\u001b[0m : values\n"
     ]
    }
   ],
   "source": [
    "cleaned_train=cleaning(x_train)\n",
    "cleaned_test=cleaning(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24211d08-d8ed-4560-9e08-ec9d548abb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3fedf38-1ce9-4e49-b2fa-906e160dda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_train=preprocessing(cleaned_train,col='message')\n",
    "prep_test=preprocessing(cleaned_test,col='message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c9357f-4d0f-4313-9683-8ff1d61186d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train[prep_train.index]\n",
    "y_test=y_test[prep_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a53f3165-2f49-4741-9c35-8246e636689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb=LabelEncoder()\n",
    "y_train=lb.fit_transform(y_train)\n",
    "y_test=lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a094d1cb-a6b9-449f-9da4-0a6a10245980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0206f85a-2484-46f0-bbee-3ced40e9ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does we cound vacab before cleaning and removing stopwords or without removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f12d368-7815-4a45-b213-4d4a985b492b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                 Will ü b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f45b80c-9b80-422e-abbe-816355e44ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# text = ' '.join(x)\n",
    "# words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "# unique_words = set(words)\n",
    "# vocab_size = len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "265413b2-4d02-4a27-928f-2e8653c77231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4552426c-e968-4737-b85b-33d22ec7a459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5431"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_size=10000\n",
    "maxlen=66\n",
    "tokenizer=Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(prep_train['message'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eae200ad-3601-4847-90e4-ee32020c97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=tokenizer.texts_to_sequences(prep_train['message'])\n",
    "# (num_samples, num_timesteps)\n",
    "padded_sequences=pad_sequences(sequences,padding='post',maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ec1dd98-10e6-4cc1-a6fd-91f1e3a26092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3523, 66)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8418bccb-70d0-4517-a8bf-164a6dca9038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 268,   11,  682, ...,    0,    0,    0],\n",
       "       [   3,   31,  959, ...,    0,    0,    0],\n",
       "       [1730, 1348,   30, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  72,   56,   12, ...,    0,    0,    0],\n",
       "       [1046,  620, 1316, ...,    0,    0,    0],\n",
       "       [  12,   14,   35, ...,    0,    0,    0]],\n",
       "      shape=(3523, 66), dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6852736a-d7d9-4ace-8640-fe7ff9939052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbc432-747f-4eda-a3f7-7bb7ae518d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22be4ef9-3f59-40a7-b241-4cdd4539a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    # input shape (None, 66, 10000)\n",
    "    # (n_samples,n_time_steps,embed_dimen)\n",
    "    # layers.Embedding(input_dim=vocab_size,output_dim=64,input_length=66) #input_length is optional,# (None, 66, 300)\n",
    "    layers.Embedding(input_dim=vocab_size,output_dim=100),#output (None, 66, 300)\n",
    "    layers.LSTM(64),#(None, 66) \n",
    "    layers.Dense(32,activation='relu'),\n",
    "    # layers.Dropout(0.3),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "\n",
    "])\n",
    "# 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ab7f22-6dcf-4d75-8a0f-df0727a7687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8520 - loss: 0.4215 - val_accuracy: 0.8596 - val_loss: 0.4082\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8705 - loss: 0.3878 - val_accuracy: 0.8596 - val_loss: 0.4089\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8705 - loss: 0.3880 - val_accuracy: 0.8596 - val_loss: 0.4095\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8705 - loss: 0.3887 - val_accuracy: 0.8596 - val_loss: 0.4058\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8705 - loss: 0.3900 - val_accuracy: 0.8596 - val_loss: 0.4061\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8705 - loss: 0.3878 - val_accuracy: 0.8596 - val_loss: 0.4057\n",
      "Epoch 7/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8705 - loss: 0.3861 - val_accuracy: 0.8596 - val_loss: 0.4063\n",
      "Epoch 8/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8705 - loss: 0.3875 - val_accuracy: 0.8596 - val_loss: 0.4059\n",
      "Epoch 9/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8705 - loss: 0.3867 - val_accuracy: 0.8596 - val_loss: 0.4076\n",
      "Epoch 10/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8705 - loss: 0.3861 - val_accuracy: 0.8596 - val_loss: 0.4058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x153d9fca660>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(padded_sequences,y_train,validation_split=0.2,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "689e5726-b402-410f-9cf3-ef18ca68f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential([\n",
    "    # input shape (None, 66, 300)\n",
    "    # (n_samples,n_time_steps,embed_dimen)\n",
    "    layers.Embedding(input_dim=vocab_size,output_dim=100),#output (None, 66, 300)\n",
    "    layers.Bidirectional(layers.GRU(64,return_sequences=True)),\n",
    "    layers.Bidirectional(layers.GRU(64)),\n",
    "    layers.Dense(32,activation='relu'),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "\n",
    "])\n",
    "# 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de9b6016-6dfd-49bd-be32-24a2de7fdf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.8875 - loss: 0.3005 - val_accuracy: 0.9603 - val_loss: 0.1218\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.9876 - loss: 0.0491 - val_accuracy: 0.9787 - val_loss: 0.0835\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.9968 - loss: 0.0173 - val_accuracy: 0.9816 - val_loss: 0.0849\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.9975 - loss: 0.0080 - val_accuracy: 0.9716 - val_loss: 0.1077\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9816 - val_loss: 0.0961\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.9830 - val_loss: 0.0952\n",
      "Epoch 7/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.0589e-04 - val_accuracy: 0.9830 - val_loss: 0.1045\n",
      "Epoch 8/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 1.5667e-04 - val_accuracy: 0.9830 - val_loss: 0.1091\n",
      "Epoch 9/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 1.1344e-04 - val_accuracy: 0.9830 - val_loss: 0.1131\n",
      "Epoch 10/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 8.7836e-05 - val_accuracy: 0.9830 - val_loss: 0.1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x153da0ea490>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model2.fit(padded_sequences,y_train,validation_split=0.2,epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac7d0974-34b5-4a3f-a183-1e9835e1582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], shape=(3523,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73eb6318-d068-439c-8b23-e45fe200c9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">543,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m543,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m42,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,762,361</span> (6.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,762,361\u001b[0m (6.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">587,453</span> (2.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m587,453\u001b[0m (2.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,174,908</span> (4.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,174,908\u001b[0m (4.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32189337-2d5a-427b-b52a-0243719344b2",
   "metadata": {},
   "source": [
    "# Try using embedding (None,300,1)\n",
    "make each message being represented with one vector of size 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c61f54ad-f43b-44b6-857e-aaaf599c84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v=np.zeros((len(prep_train),300))\n",
    "test_v=np.zeros((len(prep_test),300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5739564f-047d-41f1-96b5-f93c3a638c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d99bb0ba-4fe1-44af-b3bc-b3c6471ca629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a6e3262c98488791bd919baee32df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3523 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,doc in tqdm(enumerate(nlp.pipe(prep_train['message'])),total=len(prep_train)):\n",
    "    train_v[i,:] =doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8af1ae16-6a78-4fee-828e-8acd8f650b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0279815 , -0.269225  , -0.23353499, ...,  0.100813  ,\n",
       "        -0.03346   ,  0.26445001],\n",
       "       [-0.1392675 ,  0.1478274 , -0.12691452, ..., -0.2005147 ,\n",
       "         0.13427116,  0.10181274],\n",
       "       [ 0.15467668, -0.021534  , -0.00230667, ...,  0.01061   ,\n",
       "         0.07159001, -0.10689136],\n",
       "       ...,\n",
       "       [-0.0696772 ,  0.10397701, -0.16257419, ..., -0.0448302 ,\n",
       "         0.1180622 ,  0.0576344 ],\n",
       "       [-0.28794026,  0.00544374, -0.11241525, ...,  0.09337795,\n",
       "         0.12980551,  0.21480799],\n",
       "       [-0.0931615 ,  0.2744745 , -0.42537424, ..., -0.12483674,\n",
       "         0.08389725,  0.14581725]], shape=(3523, 300))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f015558-a687-4f8f-bc54-3519aaa84ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f1a0f92d-268d-4243-af54-9979b81f3db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e2262de265440a9278c67adbc985db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1774 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,doc in tqdm(enumerate(nlp.pipe(prep_test['message'])),total=len(prep_test)):\n",
    "    test_v[i,:] =doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3cb10576-e161-498b-9b0b-30d08af6e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v=np.expand_dims(train_v,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2db26e76-9541-4168-a88b-61f05fadcd3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3523, 300, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d41751e9-fff0-40ba-8688-b1f1b4fcc109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential([\n",
    "#     # input shape (None, 66, 300)\n",
    "#     # (n_samples,n_time_steps,embed_dimen)\n",
    "#     # layers.Embedding(input_dim=vocab_size,output_dim=100),#output (None, 66, 300)\n",
    "#     layers.Bidirectional(layers.GRU(64,return_sequences=True)),\n",
    "#     layers.Bidirectional(layers.GRU(64)),\n",
    "#     layers.Dense(32,activation='relu'),\n",
    "#     layers.Dense(1,activation='sigmoid')\n",
    "\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e2174657-11e2-4d3c-8cb4-5ca58c4a36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    # input shape (None, 66, 10000)\n",
    "    # (n_samples,n_time_steps,embed_dimen)\n",
    "    # layers.Embedding(input_dim=vocab_size,output_dim=128,input_length=66),# (None, 66, 300)\n",
    "    layers.LSTM(32,return_sequences=True),#(None, 66) \n",
    "    layers.LSTM(16,return_sequences=True),#(None, 66) \n",
    "    layers.Dropout(0.3),\n",
    "    layers.LSTM(8),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3138f768-580a-4905-947e-7e1bb2583a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "54d01f15-2990-4e04-96ab-e74fa03e34bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 347ms/step - accuracy: 0.8669 - loss: 0.4339 - val_accuracy: 0.8596 - val_loss: 0.3966\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 336ms/step - accuracy: 0.8705 - loss: 0.3704 - val_accuracy: 0.8596 - val_loss: 0.3645\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 338ms/step - accuracy: 0.8705 - loss: 0.3291 - val_accuracy: 0.8596 - val_loss: 0.3086\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 343ms/step - accuracy: 0.8705 - loss: 0.2954 - val_accuracy: 0.8582 - val_loss: 0.2894\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 349ms/step - accuracy: 0.8896 - loss: 0.2532 - val_accuracy: 0.8922 - val_loss: 0.2485\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 345ms/step - accuracy: 0.9017 - loss: 0.2337 - val_accuracy: 0.8950 - val_loss: 0.2229\n",
      "Epoch 7/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 345ms/step - accuracy: 0.9095 - loss: 0.2137 - val_accuracy: 0.9021 - val_loss: 0.2363\n",
      "Epoch 8/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 345ms/step - accuracy: 0.9088 - loss: 0.2110 - val_accuracy: 0.9106 - val_loss: 0.2092\n",
      "Epoch 9/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 349ms/step - accuracy: 0.9145 - loss: 0.2015 - val_accuracy: 0.9191 - val_loss: 0.2108\n",
      "Epoch 10/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 343ms/step - accuracy: 0.9166 - loss: 0.1990 - val_accuracy: 0.9163 - val_loss: 0.2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17f447f89d0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_v,y_train,validation_split=0.2,epochs=10,batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
